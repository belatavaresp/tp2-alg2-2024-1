{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do problema (k-centros)\n",
    "Dado um conjunto de $n$ pontos e um parâmetro $k$, deseja-se encontrar $k$ centros de forma que os pontos estejam o mais próximo possível desses centros (cada ponto está localizado a uma distância máxima $r$ de um dos centros).\n",
    "\n",
    "**Entrada:** Conjunto de pontos $S = {s_1, s_2, ..., s_n}$; Função(métrica) de distância $\\text{dist}: S \\times S \\rightarrow \\mathbb{R}^+$; Inteiro (número de centros) $k$.\n",
    "\n",
    "**Saída:** Conjunto de centros $C = {c_1, c_2, ..., c_k}$\n",
    "\n",
    "**Objetivo:** minimizar o $r$ máximo dos clusters, $r(C) = \\max \\{ \\text{dist}(s_i, C) \\}$ onde $\\text{dist}(s_i, C) = \\min \\{ \\text{dist}(s_i, c_j) \\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset (Wine)\n",
    "\n",
    "wine = fetch_ucirepo(id=109)   \n",
    "# absenteeism_at_work = fetch_ucirepo(id=445) \n",
    "# dry_bean = fetch_ucirepo(id=602) \n",
    "# rice_cammeo_and_osmancik = fetch_ucirepo(id=545) \n",
    "# raisin = fetch_ucirepo(id=850) \n",
    "# wine_quality = fetch_ucirepo(id=186) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados (datasets tipo pandas)\n",
    "\n",
    "# Wine\n",
    "X = wine.data.features # features de cada vinho (178 x 13), tipo contínuo/int\n",
    "y = wine.data.targets  # classes dos vinhos (178 x 1), existem 3 classes distintas\n",
    "\n",
    "# Ausência no trabalho 740 instâncias \n",
    "# X = absenteeism_at_work.data.features \n",
    "# y = absenteeism_at_work.data.targets \n",
    "# print(y)\n",
    "\n",
    "# Dry Bean 13611 instâncias\n",
    "# X = dry_bean.data.features \n",
    "# y = dry_bean.data.targets\n",
    "# print(y) \n",
    "\n",
    "# Rice 3810 instâncias\n",
    "# X = rice_cammeo_and_osmancik.data.features \n",
    "# y = rice_cammeo_and_osmancik.data.targets \n",
    "\n",
    "# Raisins 900 instâncias\n",
    "# X = raisin.data.features \n",
    "# y = raisin.data.targets \n",
    "\n",
    "# Wine quality\n",
    "# X = wine_quality.data.features \n",
    "# y = wine_quality.data.targets \n",
    "\n",
    "samples = X.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Métricas:*** Distância de Minkowski\n",
    "A distância entre dois pontos $x$ e $y$ em $\\mathbb{R}^n$ é dada por:\n",
    "\n",
    "$$\n",
    "\\text{dist}(x, y) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{\\frac{1}{p}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_dist(x,y,p):\n",
    "    # x, y -> tuplas\n",
    "    # p -> int\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    d = 0\n",
    "    \n",
    "    d = np.sum(np.power(np.abs(x - y), p))\n",
    "    \n",
    "    return np.power(d, 1 / p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizes de distância entre os pontos \n",
    "$p=1$: Distância de Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistMatrix(samp, X, p):\n",
    "    matrix = np.zeros((samp, samp))\n",
    "    for i in range(samp):\n",
    "        for j in range(i + 1, samp):\n",
    "            dist = minkowski_dist(X[i], X[j], p)\n",
    "            matrix[i, j] = dist\n",
    "            matrix[j, i] = dist  # simetria\n",
    "    return matrix\n",
    "            \n",
    "X_arr = X.to_numpy() if hasattr(X, 'to_numpy') else np.array(X) # convertendo o dataset pra numpy (evitar erro de indexação)\n",
    "manhattan_d = getDistMatrix(samples, X_arr, p=1)\n",
    "print(manhattan_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p=2$: Distância Euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclid_d = getDistMatrix(samples, X_arr, p=2)\n",
    "print(euclid_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada: número N de samples, número k de centros, matriz dist de distâncias\n",
    "# Saída: raio r, seguido de uma lista com os índices dos k centros escolhidos\n",
    "# A escolha do primeiro centro é aleatória.\n",
    "\n",
    "def alg_maiores_distancias(N, k, dist):\n",
    "    ans = []\n",
    "    ans.append(random.randrange(N))\n",
    "    for i in range(k-1):\n",
    "        best = -math.inf\n",
    "        center = None\n",
    "        for p in range(N):\n",
    "            val = math.inf\n",
    "            for q in ans:\n",
    "                val = min(val, dist[p][q])\n",
    "            if val > best:\n",
    "                center = p\n",
    "                best = val\n",
    "        ans.append(center)\n",
    "\n",
    "    r = -math.inf\n",
    "    for p in range(N):\n",
    "        best = math.inf\n",
    "        for q in ans:\n",
    "            best = min(best, dist[p][q])\n",
    "        r = max(r, best)\n",
    "\n",
    "    return r, ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_maiores_distancias(samples, 4, euclid_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_busca_binaria(N, k, dist, precision=0.01):\n",
    "    rmax = 0 \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            rmax = max(rmax, dist[i][j])\n",
    "    lower_bound = 0\n",
    "    upper_bound = rmax\n",
    "    ans = []\n",
    "    while upper_bound - lower_bound >= precision * rmax:\n",
    "        mid = (upper_bound + lower_bound)/2\n",
    "        centros = []\n",
    "        coberto = [False] * N\n",
    "        sobra = list(range(N))\n",
    "        while len(sobra) > 0 :\n",
    "            centro = random.choice(sobra)\n",
    "            centros.append(centro)\n",
    "            for p in range(N):\n",
    "                if dist[p][centro] <= mid:\n",
    "                    coberto[p] = True\n",
    "            sobra = []\n",
    "            for p in range(N):\n",
    "                if coberto[p] == False:\n",
    "                    sobra.append(p)\n",
    "        if len(centros) <= k:\n",
    "            upper_bound = mid\n",
    "            ans = centros\n",
    "        else:\n",
    "            lower_bound = mid\n",
    "    return upper_bound, ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_busca_binaria(samples, 4, euclid_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados sintéticos\n",
    "### Scikit Learn\n",
    "Snippet de código obtido na referência: https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets creation\n",
    "n_samples = 500\n",
    "seed = 30\n",
    "\n",
    "noisy_circles = datasets.make_circles(\n",
    "    n_samples=n_samples, factor=0.5, noise=0.05, random_state=seed\n",
    ")\n",
    "\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=seed)\n",
    "\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=seed)\n",
    "\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "no_structure = rng.rand(n_samples, 2), np.zeros(n_samples)\n",
    "\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "varied = datasets.make_blobs(\n",
    "    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state\n",
    ")\n",
    "\n",
    "data = [\n",
    "    noisy_circles,  \n",
    "    noisy_moons,    \n",
    "    varied,         \n",
    "    aniso,          \n",
    "    blobs,         \n",
    "    no_structure,  \n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"noisy_circles\",\n",
    "    \"noisy_moons\",\n",
    "    \"varied_blobs\",\n",
    "    \"aniso_blobs\",\n",
    "    \"blobs\",\n",
    "    \"no_structure\"\n",
    "]\n",
    "\n",
    "labeled_data = [(X, y, label) for (X, y), label in zip(data, labels)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 9))\n",
    "for i, (X, y) in enumerate(data):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color=\"b\")\n",
    "    plt.title(f\"Dataset {i+1}\")\n",
    "    plt.xlim(-2.5, 2.5)\n",
    "    plt.ylim(-2.5, 2.5)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "def calculate_and_plot_2d_clusters(X, k, ax, title, p):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    n_samples = X.shape[0]\n",
    "    dist_matrix = getDistMatrix(n_samples, X, p)\n",
    "\n",
    "    # alg_maiores_distancias\n",
    "    r_maiores, centers_maiores = alg_maiores_distancias(n_samples, k, dist_matrix)\n",
    "    labels_maiores = np.zeros(n_samples, dtype=int)\n",
    "    for p in range(n_samples):\n",
    "        distances_to_centers = [dist_matrix[p][center] for center in centers_maiores]\n",
    "        labels_maiores[p] = np.argmin(distances_to_centers)\n",
    "\n",
    "    # alg_busca_binaria\n",
    "    r_busca, centers_busca = alg_busca_binaria(n_samples, k, dist_matrix)\n",
    "    labels_busca = np.zeros(n_samples, dtype=int)\n",
    "    for p in range(n_samples):\n",
    "        distances_to_centers = [dist_matrix[p][center] for center in centers_busca]\n",
    "        labels_busca[p] = np.argmin(distances_to_centers)\n",
    "\n",
    "    # Plot    \n",
    "    ax[0].scatter(X[:, 0], X[:, 1], c=[colors[label % len(colors)] for label in labels_maiores], s=10)\n",
    "    ax[0].set_title(f\"{title} - alg_1\")\n",
    "    ax[0].set_xlim(-2.5, 2.5)\n",
    "    ax[0].set_ylim(-2.5, 2.5)\n",
    "    ax[0].set_xticks(())\n",
    "    ax[0].set_yticks(())\n",
    "\n",
    "    ax[1].scatter(X[:, 0], X[:, 1], c=[colors[label % len(colors)] for label in labels_busca], s=10)\n",
    "    ax[1].set_title(f\"{title} - alg_2\")\n",
    "    ax[1].set_xlim(-2.5, 2.5)\n",
    "    ax[1].set_ylim(-2.5, 2.5)\n",
    "    ax[1].set_xticks(())\n",
    "    ax[1].set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "k=3\n",
    "for i, (X, y) in enumerate(data):\n",
    "    if X is not None:\n",
    "        ax = plt.subplot(4, 4, 2 * i + 1)\n",
    "        calculate_and_plot_2d_clusters(X, k, [ax, plt.subplot(4, 4, 2 * i + 2)], f\"Dataset {i+1}\", p=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y_true, labels, metric=\"euclidean\"):\n",
    "    silhouette = silhouette_score(X, labels, metric=metric)\n",
    "    rand_index = adjusted_rand_score(y_true, labels)\n",
    "    return silhouette, rand_index\n",
    "\n",
    "def run_maiores_distancias(datasets, k=3, num_executions=30):\n",
    "    results = []\n",
    "    \n",
    "    for X, y_true, label in datasets:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        N = len(X)\n",
    "        \n",
    "        for p in [1, 2]:\n",
    "            dist_matrix = getDistMatrix(N, X, p)\n",
    "            distance_type = \"Manhattan\" if p == 1 else \"Euclidean\"\n",
    "            \n",
    "            for _ in range(num_executions):\n",
    "                start_time = time.time()\n",
    "                r, centers = alg_maiores_distancias(N, k, dist_matrix)\n",
    "                exec_time = time.time() - start_time\n",
    "                \n",
    "                labels = np.argmin(dist_matrix[:, centers], axis=1)\n",
    "                \n",
    "                silhouette, rand_index = evaluate(X, y_true, labels)\n",
    "                \n",
    "                results.append([label, distance_type, r, silhouette, rand_index, exec_time])\n",
    "    \n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "def save_csv(results, filename=\"clustering_results.csv\"):\n",
    "    header = [\"Dataset\", \"Distance\", \"Radius\", \"Silhouette Score\", \"Adjusted Rand Index\", \"Execution Time\"]\n",
    "\n",
    "    with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_maiores_distancias(labeled_data)\n",
    "save_csv(results, filename=\"cluster_sintetico_1.csv\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição normal multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(dts=10, cts=3, points_center=100, desv=None):\n",
    "    if desv is None:\n",
    "        desv = [0.1, 0.5, 1.0]  # desvios: baixo, médio e alto\n",
    "    datasets = []\n",
    "\n",
    "    ind = 1\n",
    "    for desvio in desv:\n",
    "        for _ in range(dts):\n",
    "            centers = np.random.rand(cts, 2) * 4 - 2\n",
    "            X = []\n",
    "            y = []\n",
    "            for i, center in enumerate(centers):\n",
    "                points = np.random.multivariate_normal(center, np.eye(2) * desvio, points_center)\n",
    "                X.append(points)\n",
    "                y.append(np.full(points_center, i))\n",
    "            X = np.vstack(X)\n",
    "            y = np.hstack(y)\n",
    "            datasets.append((X, y, f\"{ind}: {desvio}\"))\n",
    "            ind += 1\n",
    "            \n",
    "    return datasets\n",
    "\n",
    "# gerando os conjuntos de dados\n",
    "data_2 = generate_datasets()\n",
    "\n",
    "# Plots\n",
    "def plot_generated_datasets(datasets):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (X, y, title) in enumerate(datasets):\n",
    "        ax = plt.subplot(5, 6, i + 1)\n",
    "        cluster_colors = [colors[label % len(colors)] for label in y]\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=cluster_colors, s=10)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_generated_datasets(data_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = len(data_2)\n",
    "n_rows = (n_datasets * 2 + 1) // 6\n",
    "plt.figure(figsize=(15, n_rows*2))\n",
    "\n",
    "for i, (X, y, title) in enumerate(data_2):\n",
    "    ax = plt.subplot(n_rows, 6, 2 * i + 1)\n",
    "    calculate_and_plot_2d_clusters(X, k=3, ax=[ax, plt.subplot(n_rows, 6, 2 * i + 2)], title=title, p=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_maiores_distancias(data_2)\n",
    "save_csv(results, filename=\"cluster_sintetico_2.csv\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
